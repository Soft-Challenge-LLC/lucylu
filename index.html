<!DOCTYPE HTML>
<!--
	Dimension by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Lucy Lu, Ph.D.</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<div class="logo">
							<span class="icon fa-gem"></span>
						</div>
						<div class="content">
							<div class="inner">
								<h1>Lucy Lu, Ph.D.</h1>
								<p>

								</p>
							</div>
						</div>
						<nav>
							<ul>
								<li><a href="#intro">Intro</a></li>
								<li><a href="#work">Work</a></li>
								<li><a href="#about">About</a></li>
								<li><a href="#contact">Contact</a></li>
								<!--<li><a href="#elements">Elements</a></li>-->
							</ul>
						</nav>
					</header>

				<!-- Main -->
					<div id="main">

						<!-- Intro -->
							<article id="intro">
								<h2 class="major">Intro</h2>
								<span class="image main"><img src="images/pic01.jpg" alt="" /></span>
								<h3>Education:</h3>
								<ul>
									<li>University of South Florida, Computer Science. Ph. D, 2016-2023</li>
									<li>University of South Florida, MUMA Business School. MBA, 2018-2022</li>
									<li>Tsinghua University, Computer Science. B.S, 2002</li>
									<li>Tsinghua University, Computer Science. M.S, 2005</li>
								</ul>
									<h3>Certificates:</h3>
								<ul>
									<li>Data Science Fellow, The Data Incubaot, 2020</li>
									<li>Google Analytics for Beginners, 2017</li>
									<li>Advanced Google Analytics, 2017</li>
									<li>MIT Big Data and Social Behavior, 2018</li>
								</ul>
								<h3>Skills:</h3>
								<ul>
									<li>Programming Languages: Python, R, Java, C, VBA, SQL</li>
									<li>Database: Oracle, Microsoft SQL Server, MySQL, Postgres</li>
									<li>Information System: SAP, ArcGIS, Google Analytics</li>
									<li>Data Analysis: Machine Learning, Data Modeling, Data Quality Control, Data Visualization</li>
									<li>Expertise: Text Mining, Image Processing, Social Network Analysis</li>
								</ul>
									<h3>Professional Work:</h3>
								<ul>
									<li>Employer: National Center for Toxicological Research, January, 2006-December, 2015</li>
									<li>Employer: Soft Challenge LLC, Tampa, Florida, February, 2012-now</li>
								</ul>
								<h3>Internship Work:</h3>
								<ul>
									
									<li>TCM Bank LLC, February, 2020 – April, 2020</li>
									<li>credit risk modeling and analysis.</li>
									<li>operational risk modeling and analysis,</li>
									<li>market risk modeling and analysis,</li>
									<li>fraud risk modeling and analysis.</li>
									<li>Executive Management Report Automation and Delivery.</li>
								</ul>
								<ul>
									<li>Quality Counts LLC, March, 2019- August, 2020</li>
									<li>traffic detection</li>
									<li>travel planning</li>
									<li>congestion detection</li>
									<li>transportation planning</li>
									<li>curve safety analysis</li>
								</ul>
								<ul>
									<li>Geographic Solutions, January, 2018 – June, 2019</li>
									<li>population group and interpretation</li>
									<li>Key performance indicator (KPI) definition and evaluation
									located based job market analysis</li>
								</ul>
									<h3>Awards:</h3>
								<ul>
									<li>Best Paper Award, at WMSCI 2016 Conference, for the paper titled “Combining Bayesian and Semantic Analysis with Domain Knowledge”</li>
									<li>Best Paper Award, at WMSCI 2013, for the paper titled “Discovery of Strong Association Rules for Attributes from Data for Program of All-Inclusive Care for the Elderly (PACE)”</li>
									<li>Best Poster Award, at National Science Foundation (NSF) Bioinformatics Workshop to Foster Collaborative Research 2013, for the poster titled “Linkage Discovery with Glossaries and Topic Segmentation”</li>
									<li>Microsoft Innovation Cup Student Software Contest, 1st Place. 2005</li>
									<li>Best Paper Award, at WMSCI 2011 Conference, for the paper titled “Statistical Quality Control of Microarray Gene Expression Data”</li>
									<li>BEA Scholarship, 2005</li>
									<li>Guanghua Scholarship, 2004</li>
									<li>Tsinghua Scholarship, 2003</li>
								</ul>
							</article>

						<!-- Work -->
							<article id="work">
								<h2 class="major">Projects</h2>
								<span class="image main"><img src="images/pic02.jpg" alt="" /></span>
<div id="top">
	<ul>
		<li><a href="#image-processing">Image Processing</a>
			<ol style="list-style-type: lower-alpha; padding-bottom: 0;">
			  <li style="margin-left:2em"><a href="#edge-detection">Edge Detection</a></li>
			  <li style="margin-left:2em; padding-bottom: 0;"><a href="#object-detection">Object Detection</a></li>
			 </ol>
		</li>
		<li><a href="#text-mining">Text Analysis</a>
			 <ol style="list-style-type: lower-alpha; padding-bottom: 0;">
			  <li style="margin-left:2em"><a href="#online-news">Online News Popularity Prediction</a></li>
			  <li style="margin-left:2em; padding-bottom: 0;"><a href="#text-classification">Featured Transformer Model (FTM) for Text Classification</a></li>
			  <li style="margin-left:2em"><a href="#entity-detection">Entity Extraction through Conditional Random Fields model (CRF)</a></li>
			 </ol>
		</li>
		<li><a href="#social-graph">Social Graph Analysis</a></li>
		<li><a href="#fraud-detection">Credit Card Fraud Detection</a></li>
	</ul>
</div>


<div id='image-processing'>
<h2>Image Processing</h2>
<p>
	In image processing, we focus on edge detection and object detection. For edge detection, we use Conditional Random Fields (CRF) to improve the existing edge detection methdology. We detect all edges with closed lines and without duplicate edges. For object detection, we add arbitrary features to the objects to deep learning model to enforce deep learning model to learn the characteristics of specific objects.
	<ul>
		<li><a href="#edge-detection">Edge Detection</a></li>
		<li><a href="#object-detection">Object Detection</a></li>
	</ul>
</p>
</div>

<div id="edge-detection">
<h3>Edge Detection</h3>
<p>
	The challenge in line segmentation is that the threshold of the gradients have to be determined in the first place, a set of criteria  are needed to define the properties of line segments,  fractions of the image need to be detected, the validation of the line segment is also determined arbitrarily. We proposed a sematic line segmentation detection model based on conditional random fields (CRF) model. Based on the gradients of the image, this methodology does not require any prior knowledge about the image, no fraction selection, no threshold, no criteria for region growth and rectangle validation. 
</p>
<h5>Methodology</h5>
<p>
	CRF model, as shown in figure 1, can be considered as Markov random fields model. The initial transition probability of each pixel is the same. During each iteration, the state function can average out the different among neighbors and the transition function update the featured pixels. Apparently, state function make the local pixels similar to each other. This operation is especially useful when some pixels are changed because of noise or system errors. When the significance of each pixel is computed not only with the value of the pixel itself but also the values of the adjacent neighbors, system errors and arbitrary noise can be average out. Feature function is defined with the features we pick so that it can consistently increase the significance of features and depress the significance of none features. 
</p>
<img style="margin-left:auto;margin-right:auto;" src="images/CRF.png"></img>
<p>Figure 1. Conditional Random Fields Model</p>
<h5>Performance</h5>
<p>
	We tested the methodology with several images, such as, the image of simple lines, the image of simple objects, and the portrait of a person. We use the same feature functions and the same Gaussian kernel to detection line segments in three different images. In figure 2(a)(b)(c), we compared out results with the ones generated with Linear Time Line Segmentation Detection (LTLSD) method.
</p>

<img style="margin-left:auto;margin-right:auto;"  src="images/ip-lsd-lines.png"></img>
<p>(a)</p>
<img style="margin-left:auto;margin-right:auto;"  src="images/ip-lsd-chairs.png"></img>
<p>(b)</p>
<img style="margin-left:auto;margin-right:auto;"  src="images/ip-lsd-lena.png"></img>
<p>(c)</p>
<p>Figure 2. Comparison of CRF results with LTLSD results</p>

<p>In LTLSD result, as shown in figure 2(a), objects in the image are not closed. As shown in figure 2(b), many line segments are doubled which make the image not readable, some lines apparently are shadows but were extracted as lines. As shown in figure 2(c), in the background, a lot of lines are cut. Around the face and the hat, some small circles and short lines are not detected and some are not closed.
<p><a href="#top">Top</a></p>
</div>

<div id="object-detection">
<h3>Object Detection</h3>
<p>
Deep learning is generally used in image recognition. For example, deep learning can recognize handwriting of 10 digital numbers in MNIST data set. Deep learning does not require pre-selected feature set for training, as shown in figure 1. During training, deep learning model repeatedly select features, evaluate the quality of the feature set and generate output for next layer. However, What exactly does the deep learning model learn from the training set?</p>

<img style="margin-left:auto;margin-right:auto;"  src="images/ip-deeplearning.png"></img>
<p>Figure 1. Deep Learning Model</p>

<p>
	In image processing, there are a lot of features in one image. It is information rich. Normally, one small detail is the combination of many pixels, which is too much for human to quantitatively check each one of the computation units - the pixels. 
	<br>
	<br>
	Deep learning model selects features from entire images. If there are some common patterns which can differentiate the ten categories, those patterns can be chosen as the feature set. Some features are related to the pictures, and some features are related to the objects, but, if we don't enforce the deep learning model to learn from objects, most of the features deep learning model learned are based on the pictures, which means deep learning model does not really learn the objects. This is major flaw in this process. If we change the background of the objects, deep learning can not recognize the objects any more.
</p>
<h5>Methodology</h5>
<p>We add feature function to deep learning model so that deep learning model can be enforced to learn from the objects only, as shown in figure 2.</p>

<img style="margin-left:auto;margin-right:auto;" src="images/ip-deeplearning-enforced.png"></img>
<p>Figure 2. Feature Enforced Deep Learning Model</p>

<h5>Performance</h5>

<img style="margin-left:auto;margin-right:auto;"  src="images/ip-2layer-original.png"></img>
<p>(a) Output from Original Deep Learning Model</p>
<img style="margin-left:auto;margin-right:auto;"  src="images/ip-2layer-enforced.png"></img>
<p>(b) Output from Feature Enforced Deep Learning Model</p>
<p>Figure 2. Comparison of Features in Decision layer</p> 

In the original output in figure 2(a), we can see some feature spots which are the common patterns in different images but those patterns are not meaningful. After we add feature filter to the deep learning model, the model only picks features from object regions and the output shows the features of the objects, as shown in figure 2(b). 
<p><a href="#top">Top</a></p>
</div>


<div id='social-graph'>
<h2>Social Graph Analysis</h2>
<h3>Technology Trends</h3>
<p>
Understanding the structure of the network is central in network analysis. We are interested in extracting valuable information from the network, such as trends, popularity, dynamic of the trends, and also profiles of popular items.
<br>
<br>
This prediction model can be used for many different applications. such as 
	<ul>
		<li>Technology Trends: citation/patent network</li>
		<li>Online market: co-purchase network</li>
		<li>Social Media Trends: online news/live journal/media sharing network</li>
		<li>Social Dynamics: friends network</li>
	</ul>
</p>

<h5>Sample Data</h5>
<p>
	This is a citation graph for high-energy physics research papers from 1991 to 2000, with a total of N = 29,555 papers and E = 352,807 citations
</p>
<h5>Data Modeling</h5>
<p>
	In terms of data modeling, we need to define popular topics for each year with the citation data and also find out how many are new topics. In each popular topic, we need to find density of the topic, the change of the density in ten years, the diameter of the topic and the change of the diameter in ten years. 
	<br>
	<br>
	Lots of features are unknown in the citation network. For example, we don’t know the related topics of the papers. we don’t know how to define the popularity because we don’t have a big picture of the citation network. We can start from any paper and search along the path through the entire network. Whatever we can find is highly related to where we started. The citation network is so big that it is not feasible to try all of the papers. Also, we know that greedy search in the network is NP-hard. It is impossible to get it done in polynomial time.
</p>
<h5>Methodology</h5>
<p>
	We decompose the network into two layers, as shown in figure 1. We use kronecker graph in figure 2(a) as the computation unit. Kronecker graph is the smallest symmetric graph and also is the smallest community in social network. Symmetric graph has structural properties and the mathematical properties which can support the decomposition and reconstruction. 
</p>

<img style="margin-left:auto;margin-right:auto;" src="images/interesting-layer.png"></img>
<p><b>Figure 1. Network Decomposition</b></p>
<img style="margin-left:auto;margin-right:auto;" src="images/kronecker-graph.png"></img>
<p><b>Figure 2(a). Kronecker Graph</b></p>
<img style="margin-left:auto;margin-right:auto;" src="images/kronecker-join.png"></img>
<p><b>Figure 2(b). Graph Join and Project</b></p>

<h5>Results</h5>
<p>
From 1991 to 2000, we summarized the number of nodes (papers and references), the number of edges (citations), maximum number of times that a paper was cited, the averages number of times that a paper was cited, as shown in figure 3. </p>

<img style="margin-left:auto;margin-right:auto;" src="images/stats-citation.png"></img>
<p><b>Figure 3. Statistics of Co-citation from 1991 to 2000</b></p>

<p>
	Each co-citation defines a topic so that the frequent co-citations define the popular topics. The frequency of the co-citation is highly biased. We use Expectation Maximization (EM) to group co-citations into 3 clusters, and statistics of popular topics is shown in figure 4. From 1991 to 2000, the number of publications, citations, and co-citations increase. From 1991 to 1995, there are less publications, citations, and co-citations. After 1995, the increase of publications, citations, and co-citations is not as fast as those years from 1991 to 1995. The number of topics increases from 1991 to 1994. After 1994, the change in the number of topics each year is small. Sometimes, it goes up and sometimes, it goes down, and it is around the average of 800 topics each year. 
</p>

<img style="margin-left:auto;margin-right:auto;" src="images/stats-topics.png"></img>
<p><b>Figure 4. Statistics of Popular Topics from 1991 to 2000</b></p>

<p>
	These trends of research in10 years indicate that technology evolves every five years and can be completely updated in 10 years. When we work the frontier research, we need to trace back for about 5 years. In more than 5 years, most of the research is about something else. The trends of new publications, citation, and co-citations are consistent which can prove each other.
</p>
<p>
	The number of topics increase from 1991 to 1994. In 1991, there are no paper published about the popular topics in 2000. From 1995 to 2000, the number of topics is almost stable. the number of topics goes up and down but the changes are small.  The number of topics is consistent with the number of publications, the number of citations, the number of co-citations. 
</p>

<img style="margin-left:auto;margin-right:auto;" src="images/network-topics.png"></img>
<p><b>Figure 5. Citation Network on Popular Topics from 1992 to 2000</b></p>

<p><a href="#top">Top</a></p>
</div>



							</article>
						<!-- About -->
							<article id="about">
								<h2 class="major">About</h2>
								<span class="image main"><img src="images/pic03.jpg" alt="" /></span>
								<p>Lucy Lu is a data scientist. Her research interest is in Insights Analysis, Natural Language Processing, Entity Resolution, Deep Learning and Image Processing. She has been providing machine learning solutions in different research areas. Her research solutions have won best paper awards for three times. With her experiences in technical details, her solutions can achieve almost perfect results.</p>
							</article>

						<!-- Contact -->
							<article id="contact">
								<h2 class="major">Contact</h2>
								<form method="post" action="#">
									<div class="fields">
										<div class="field half">
											<label for="name">Lucy Lu, Ph.D.</label>
										</div>
										<div class="field half">
											<label for="email">mollielu2012@gmail.com</label>
										</div>
									</div>
								</form>
								<ul class="icons">
									<li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
									<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
									<li><a href="#" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
									<li><a href="#" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
								</ul>
							</article>


					</div>

				<!-- Footer -->
					<footer id="footer">
						<p class="copyright">&copy; Design: <a href="https://html5up.net">Lucy Lu</a>.</p>
					</footer>

			</div>

		<!-- BG -->
			<div id="bg"></div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
